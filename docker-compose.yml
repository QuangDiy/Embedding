version: '3.8'

services:
  model_downloader:
    image: python:3.10-slim
    container_name: model-downloader
    working_dir: /work
    environment:
      - HF_TOKEN=${HF_TOKEN:-}
    volumes:
      - ./:/work:ro
      - ./model_repository:/work/model_repository
    command: /bin/sh -lc "pip install --no-cache-dir huggingface_hub && python /work/download_with_hf.py"
    restart: "no"
    networks:
      - triton-network

  triton:
    image: nvcr.io/nvidia/tritonserver:24.08-py3
    container_name: triton-server
    command: tritonserver --model-repository=/models --backend-config=onnxruntime,default-max-batch-size=32
    volumes:
      - ./model_repository:/models
    ports:
      - "8001:8001"  # gRPC
      - "8002:8000"  # HTTP
      - "8003:8002"  # Metrics
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    depends_on:
      model_downloader:
        condition: service_completed_successfully
    networks:
      - triton-network

  api:
    build:
      context: .
      dockerfile: dockerfile
    container_name: jina-embeddings-v3-api
    ports:
      - "8000:8000"
    volumes:
      - ./model_repository/jina-embeddings-v3/1:/tokenizer:ro
    environment:
      - TRITON_URL=triton:8000
      - MODEL_NAME=jina-embeddings-v3
      - TOKENIZER_PATH=/tokenizer
    depends_on:
      model_downloader:
        condition: service_completed_successfully
      triton:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - triton-network

networks:
  triton-network:
    driver: bridge

